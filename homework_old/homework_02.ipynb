{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a60bffde",
      "metadata": {
        "id": "a60bffde"
      },
      "source": [
        "# HW02: Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ed3f1a",
      "metadata": {
        "id": "b8ed3f1a"
      },
      "source": [
        "Remember that these homework work as a completion grade. **You can skip one section without losing credit.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dc19cf83",
      "metadata": {
        "id": "dc19cf83",
        "outputId": "adb55c5e-fce5-4caf-bc13-221427fce116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-27 14:04:18--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29470338 (28M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  28.10M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-02-27 14:04:19 (227 MB/s) - ‘train.csv’ saved [29470338/29470338]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                              title  \\\n",
              "0  business  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
              "1  business    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
              "2  business  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
              "3  business  Oil prices soar to all-time record, posing new...   \n",
              "4  business        Stocks End Up, But Near Year Lows (Reuters)   \n",
              "\n",
              "                                                lead  \\\n",
              "0  Reuters - Private investment firm Carlyle Grou...   \n",
              "1  Reuters - Soaring crude prices plus worries\\ab...   \n",
              "2  Reuters - Authorities have halted oil export\\f...   \n",
              "3  AFP - Tearaway world oil prices, toppling reco...   \n",
              "4  Reuters - Stocks ended slightly higher on Frid...   \n",
              "\n",
              "                                                text  \n",
              "0  Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
              "1  Oil and Economy Cloud Stocks' Outlook (Reuters...  \n",
              "2  Iraq Halts Oil Exports from Main Southern Pipe...  \n",
              "3  Oil prices soar to all-time record, posing new...  \n",
              "4  Stocks End Up, But Near Year Lows (Reuters) Re...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55da979d-dbd6-4418-9f67-6d12536fd761\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n",
              "      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n",
              "      <td>Stocks End Up, But Near Year Lows (Reuters) Re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55da979d-dbd6-4418-9f67-6d12536fd761')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55da979d-dbd6-4418-9f67-6d12536fd761 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55da979d-dbd6-4418-9f67-6d12536fd761');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Import the AG news dataset (same as hw01)\n",
        "#Download them from here \n",
        "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
        "def replace_label(x):\n",
        "\treturn label_map[x]\n",
        "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f7b626",
      "metadata": {
        "id": "37f7b626"
      },
      "source": [
        "## Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ab1861a9",
      "metadata": {
        "id": "ab1861a9",
        "outputId": "1371ca19-4d9b-41f0-e6ae-dce4119f2fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Howard wins historic fourth term Prime Minister John Howard is set to become the second longest serving Prime Minister after the Coalition #39;s convincing win in yesterday #39;s federal election.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "dfs = df.sample(50)\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "##TODO use spacy to split the documents in the sampled dataframe (dfs) in sentences and tokens\n",
        "\n",
        "def split_doc(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent for sent in doc.sents]\n",
        "    tokens = [token for token in doc if not token.is_punct and not token.is_stop]\n",
        "\n",
        "    return sentences, tokens\n",
        "\n",
        "dfs['sentences'], dfs['tokens'] = zip(*dfs['text'].apply(split_doc))\n",
        "\n",
        "##TODO print the first sentence of the first document in your sample\n",
        "\n",
        "print(dfs.iloc[0]['sentences'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "65fa4c48",
      "metadata": {
        "id": "65fa4c48",
        "outputId": "c28158a2-d120-47bb-a2f5-23dddc43c9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ad16a5d24118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##TODO create a new column with tokens in lowercase (x.lower()), without punctuation tokens (x.is_punct) nor stopwords (x.is_stop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m##TODO print the tokens (x.lemma_) and the tags (x.tag_ ) of the first sentence of the first document (doc.sents)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'lower'"
          ]
        }
      ],
      "source": [
        "##TODO create a new column with tokens in lowercase (x.lower()), without punctuation tokens (x.is_punct) nor stopwords (x.is_stop)\n",
        "\n",
        "\n",
        "\n",
        "##TODO print the tokens (x.lemma_) and the tags (x.tag_ ) of the first sentence of the first document (doc.sents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e5d2b7",
      "metadata": {
        "id": "c0e5d2b7"
      },
      "source": [
        "### Noun Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57f2591",
      "metadata": {
        "id": "a57f2591"
      },
      "outputs": [],
      "source": [
        "##TODO print the first 20 noun chuncks in your sample corpus (doc.noun_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef544f1",
      "metadata": {
        "id": "8ef544f1"
      },
      "source": [
        "### Named Entities\n",
        "\n",
        "Let's compute the ratio of named entities starting with a capital letter, e.g. if we have \"University of Chicago\" as a NE, \"University\" and \"Chicago\" are capitalized, \"of\" is not, thus the ratio is 2/3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2cb111",
      "metadata": {
        "id": "be2cb111"
      },
      "outputs": [],
      "source": [
        "##TODO print the ratio of tokens being part of a named entity span starting with a capital letter (doc.ents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "984b4d1f",
      "metadata": {
        "id": "984b4d1f"
      },
      "outputs": [],
      "source": [
        "##TODO print the ratio of capitalized tokens not being part of a named entity span\n",
        "# e.g. \"The dog barks\" = 1/3; 3 tokens, only \"The\" is capitalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3ede3c",
      "metadata": {
        "id": "ac3ede3c"
      },
      "outputs": [],
      "source": [
        "##TODO print the ratio of capitalized tokens not being a named entity and not being the first token in a sentence\n",
        "# e.g. \"The dog barks\" = 0; 3 tokens, \"The\" is capitalized but the starting token of a sentence, no other tokens are capitalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df99cfb1",
      "metadata": {
        "id": "df99cfb1"
      },
      "outputs": [],
      "source": [
        "for "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466753be",
      "metadata": {
        "id": "466753be"
      },
      "source": [
        "Give an example of a capitalized token in the data which is neither a named entity nor at the start of a sentence. What could be the reason the token is capitalized (one sentence)?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3126a5c7",
      "metadata": {
        "id": "3126a5c7"
      },
      "source": [
        "## Term Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055edce8",
      "metadata": {
        "id": "055edce8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df=0.01, \n",
        "                        max_df=0.9,  \n",
        "                        max_features=1000,\n",
        "                        stop_words='english',\n",
        "                        use_idf=True, # the new piece\n",
        "                        ngram_range=(1,2))\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##TODO using the whole sample, produce a world cloud with bigrams for each label using tfidf frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a08119",
      "metadata": {
        "id": "65a08119"
      },
      "source": [
        "## Hash Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d851a0",
      "metadata": {
        "id": "f0d851a0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "hv = HashingVectorizer(n_features=5000)\n",
        "\n",
        "##TODO print the first 10 features produced by the hash vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0948e50f",
      "metadata": {
        "id": "0948e50f"
      },
      "source": [
        "## Supervised Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0510aa29",
      "metadata": {
        "id": "0510aa29"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
        "\n",
        "##TODO compute the number of words per document (excluding stopwords)\n",
        "##TODO get the most predictive features of the number of words per document using first f_class and then chi2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddaee2e4",
      "metadata": {
        "id": "ddaee2e4"
      },
      "source": [
        "Are the results different? What could be a reason for this? "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8af74a1d",
      "metadata": {
        "id": "8af74a1d"
      },
      "source": [
        "## Huggingface Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e75e4d",
      "metadata": {
        "id": "d1e75e4d"
      },
      "outputs": [],
      "source": [
        "# # we use distilbert tokenizer\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "# let's instantiate a tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "##TODO tokenize the sentences in the sampled dataframe (dfs) using the DisilBertTokenizer\n",
        "##TODO what is the type/token ratio from this tokenizer (number_of_unqiue_token_types/number_of_tokens)?\n",
        "##TODO what is the amount of subword tokens returned by the huggingface tokenizer? hint: each subword token starts with \"#\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}